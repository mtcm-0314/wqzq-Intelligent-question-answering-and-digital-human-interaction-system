import streamlit as st
import pyttsx3
import requests
import re
import json
from collections import deque
import threading
import logging
import os

# Streamlit 1.18+ æ”¯æŒ add_script_run_ctxï¼Œç”¨äºå¤šçº¿ç¨‹ä¸Šä¸‹æ–‡ä¼ é€’
from streamlit.runtime.scriptrunner import add_script_run_ctx

# ================== å…¨å±€é…ç½® ==================
_TTS_ENGINE = None
_TTS_LOCK = threading.Lock()
_TTS_ERROR_LOG = "tts_errors.log"

# ============== è‡ªå®šä¹‰æ ·å¼ ==============
st.markdown("""
<style>
.think-text {
    color: #666666;
    font-style: italic;
    border-left: 3px solid #e0e0e0;
    padding-left: 10px;
    margin: 8px 0;
    opacity: 0.8;
}
</style>
""", unsafe_allow_html=True)

# ============== åˆå§‹åŒ– TTS å¼•æ“ ==================
def init_tts_engine():
    """åˆå§‹åŒ– pyttsx3 è¯­éŸ³å¼•æ“"""
    global _TTS_ENGINE
    try:
        if _TTS_ENGINE is None:
            _TTS_ENGINE = pyttsx3.init()
            _TTS_ENGINE.setProperty('rate', 150)
            _TTS_ENGINE.setProperty('volume', 1)
            logging.info("è¯­éŸ³å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            # æµ‹è¯•è¯­éŸ³
            _TTS_ENGINE.say("ç³»ç»Ÿå°±ç»ª")
            _TTS_ENGINE.runAndWait()
            _TTS_ENGINE.endLoop()
    except Exception as e:
        logging.error(f"è¯­éŸ³åˆå§‹åŒ–å¤±è´¥: {str(e)}")

# è‹¥åœ¨ streamlit run ç¯å¢ƒä¸­ï¼Œå¯ä»¥åšä¸€æ¬¡åˆå§‹åŒ–
if os.environ.get('STREAMLIT_RUNNING'):
    init_tts_engine()

# ============== è¾…åŠ©å‡½æ•° ==================
def format_think_content(text: str) -> str:
    """
    æ ¼å¼åŒ– <think>...</think> å†…å®¹ä¸º HTML æ ·å¼å—
    åœ¨å±•ç¤ºæ—¶å°†å…¶å˜ä¸ºç°è‰²æ–œä½“å—
    """
    return re.sub(
        r'<think>(.*?)</think>',
        r'<div class="think-text">\1</div>',
        text,
        flags=re.DOTALL
    )

def tts_speak(text: str):
    """è¯­éŸ³æ’­æŠ¥ï¼šå»é™¤ <think> å†…å®¹åè°ƒç”¨ pyttsx3"""
    if not text:
        return
    try:
        with _TTS_LOCK:
            if _TTS_ENGINE is None:
                init_tts_engine()
            if _TTS_ENGINE:
                # å»æ‰ <think> æ€è€ƒæ ‡ç­¾åªè¯»å¯è§å†…å®¹
                cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
                _TTS_ENGINE.say(cleaned.strip())
                _TTS_ENGINE.runAndWait()
    except Exception as e:
        error_msg = f"è¯­éŸ³é”™è¯¯: {str(e)}"
        logging.error(error_msg)
        with open(_TTS_ERROR_LOG, "a", encoding="utf-8") as f:
            f.write(f"{error_msg}\n")

# ============== é¡µé¢ç»“æ„ ==================
st.title("æ™ºèƒ½å¯¹è¯åŠ©æ‰‹ ğŸ¤–")
st.write("æ”¯æŒæ€è€ƒè¿‡ç¨‹å¯è§†åŒ–çš„AIèŠå¤©æœºå™¨äºº")

# åˆå§‹åŒ– session_state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = deque(maxlen=20)  # ä¿å­˜æœ€è¿‘20æ¡å¯¹è¯
if "processing" not in st.session_state:
    st.session_state.processing = {"active": False, "assistant_message": ""}

# ç”¨äºæ¸²æŸ“æ‰€æœ‰å¯¹è¯çš„å®¹å™¨
chat_container = st.container()

def render_chat():
    """
    ç»Ÿä¸€åœ¨åŒä¸€ä¸ªå®¹å™¨ä¸­æ¸²æŸ“å¯¹è¯å†å² + å½“å‰æµå¼å›å¤
    """
    chat_container.empty()
    with chat_container:
        # å…ˆæ¸²æŸ“å†å²è®°å½•
        for item in st.session_state.chat_history:
            with st.chat_message(item["role"]):
                st.markdown(format_think_content(item["content"]), unsafe_allow_html=True)
        # è‹¥ AI æ­£åœ¨ç”Ÿæˆå›å¤ï¼Œåˆ™æ¸²æŸ“ä¸€ä¸ªâ€œassistantâ€æ¶ˆæ¯æ¡†æ˜¾ç¤ºæµå¼æ–‡æœ¬
        if st.session_state.processing.get("active", False):
            with st.chat_message("assistant"):
                current_text = st.session_state.processing.get("assistant_message", "")
                # ç»“å°¾åŠ ä¸ªé—ªçƒç¬¦å·
                st.markdown(format_think_content(current_text + "â–Œ"), unsafe_allow_html=True)

# ============== ä¾§è¾¹æ  ==================
with st.sidebar:
    model = st.selectbox("é€‰æ‹©æ¨¡å‹", ["deepseek-r1", "llama3", "mixtral"])
    if st.button("æ¸…ç©ºè®°å½•"):
        st.session_state.chat_history.clear()
        st.experimental_rerun()

# ============== ä¸»ä½“ï¼šç”¨æˆ·è¾“å…¥ + åå°å¤„ç† ==================
user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

if user_input and not st.session_state.processing.get("active", False):
    # 1. ç”¨æˆ·è¾“å…¥ç«‹å³æ˜¾ç¤ºåˆ°å¯¹è¯è®°å½•
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    render_chat()  # ç«‹åˆ»æ›´æ–°ç•Œé¢ï¼Œè®©ç”¨æˆ·æ¶ˆæ¯å¯è§

    # 2. è®¾ç½®å¤„ç†çŠ¶æ€ï¼Œå‡†å¤‡è·å– AI å›å¤
    st.session_state.processing = {"active": True, "assistant_message": ""}

    def get_ai_response():
        """
        åœ¨åå°çº¿ç¨‹ä¸­æµå¼è·å– AI å›å¤ï¼Œå¹¶å®æ—¶æ›´æ–°ç•Œé¢ã€‚
        """
        try:
            # æ„å»ºå†å²ä¸Šä¸‹æ–‡
            history_text = "\n".join(
                [f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state.chat_history]
            )
            # è°ƒç”¨ä½ çš„åç«¯æ¥å£ï¼Œè¿™é‡Œä»¥ localhost:11434 ä¸ºä¾‹
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": model,
                    "prompt": f"{history_text}\nAssistant:",
                    "stream": True
                },
                stream=True,
                timeout=30
            )
            response.raise_for_status()

            full_response = ""
            # æµå¼æ¥æ”¶
            for line in response.iter_lines():
                if line:
                    # è°ƒè¯•ï¼šæ‰“å°åŸå§‹è¿”å›
                    print("DEBUG raw line:", line)
                    data = json.loads(line.decode())
                    print("DEBUG parsed data:", data)

                    # å¦‚æœä½ çš„æœåŠ¡ç«¯è¿”å›çš„å­—æ®µä¸æ˜¯ 'response'ï¼Œè¯·æ”¹æˆæ­£ç¡®å­—æ®µå
                    if 'response' in data:
                        chunk = data['response']
                        full_response += chunk
                        st.session_state.processing["assistant_message"] = full_response
                        # å®æ—¶åˆ·æ–°
                        render_chat()

            # 3. å°†æœ€ç»ˆå›å¤åŠ å…¥å†å²
            st.session_state.chat_history.append({"role": "assistant", "content": full_response})

            # 4. å¯åŠ¨è¯­éŸ³æ’­æŠ¥ï¼ˆå¯é€‰ï¼‰
            threading.Thread(target=tts_speak, args=(full_response,), daemon=True).start()

        except Exception as e:
            logging.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        finally:
            # 5. æµå¼ç»“æŸï¼Œé‡ç½®å¤„ç†çŠ¶æ€
            st.session_state.processing = {"active": False, "assistant_message": ""}
            render_chat()

    # åˆ›å»ºåå°çº¿ç¨‹å¹¶ä¼ é€’å½“å‰çš„ ScriptRunContext
    worker_thread = threading.Thread(target=get_ai_response, daemon=True)
    add_script_run_ctx(worker_thread)
    worker_thread.start()

#ï¼ˆå¯é€‰ï¼‰å¦‚æœæƒ³åœ¨æ²¡æœ‰è¾“å…¥æ—¶ä¹Ÿéšæ—¶æ›´æ–°ç•Œé¢ï¼Œå¯æ”¾å¼€è¿™è¡Œ
# render_chat()
