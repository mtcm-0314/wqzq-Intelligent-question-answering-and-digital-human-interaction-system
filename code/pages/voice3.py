import streamlit as st
import pyttsx3
import requests
import re
import json
from collections import deque
import threading
import logging
import os

# ================== å…¨å±€é…ç½® ==================
_TTS_ENGINE = None
_TTS_LOCK = threading.Lock()
_TTS_ERROR_LOG = "tts_errors.log"

# ============== è‡ªå®šä¹‰æ ·å¼ ==============
st.markdown("""
<style>
.think-text {
    color: #666666;
    font-style: italic;
    border-left: 3px solid #e0e0e0;
    padding-left: 10px;
    margin: 8px 0;
    opacity: 0.8;
}
</style>
""", unsafe_allow_html=True)


# ============== åˆå§‹åŒ–å‡½æ•° ==============
def init_tts_engine():
    global _TTS_ENGINE
    try:
        if _TTS_ENGINE is None:
            _TTS_ENGINE = pyttsx3.init()
            _TTS_ENGINE.setProperty('rate', 150)
            _TTS_ENGINE.setProperty('volume', 1)
            logging.info("è¯­éŸ³å¼•æ“åˆå§‹åŒ–æˆåŠŸ")

            # æµ‹è¯•è¯­éŸ³
            _TTS_ENGINE.say("ç³»ç»Ÿå°±ç»ª")
            _TTS_ENGINE.runAndWait()
            _TTS_ENGINE.endLoop()
    except Exception as e:
        logging.error(f"è¯­éŸ³åˆå§‹åŒ–å¤±è´¥: {str(e)}")


if os.environ.get('STREAMLIT_RUNNING'):
    init_tts_engine()


# ============== åŠŸèƒ½å‡½æ•° ==============
def format_think_content(text):
    """æ ¼å¼åŒ–æ€è€ƒå†…å®¹ä¸ºå¸¦æ ·å¼çš„HTML"""
    return re.sub(
        r'<think>(.*?)</think>',
        r'<div class="think-text">\1</div>',
        text,
        flags=re.DOTALL
    )


def tts_speak(text):
    """è¯­éŸ³æ’­æŠ¥"""
    if not text:
        return

    try:
        with _TTS_LOCK:
            if _TTS_ENGINE is None:
                init_tts_engine()

            if _TTS_ENGINE:
                cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
                _TTS_ENGINE.say(cleaned.strip())
                _TTS_ENGINE.runAndWait()
    except Exception as e:
        error_msg = f"è¯­éŸ³é”™è¯¯: {str(e)}"
        logging.error(error_msg)
        with open(_TTS_ERROR_LOG, "a", encoding="utf-8") as f:
            f.write(f"{error_msg}\n")


# ============== é¡µé¢ç»„ä»¶ ==============
st.title("æ™ºèƒ½å¯¹è¯åŠ©æ‰‹ ğŸ¤–")
st.write("æ”¯æŒæ€è€ƒè¿‡ç¨‹å¯è§†åŒ–çš„AIèŠå¤©æœºå™¨äºº")

# èŠå¤©è®°å½•ç®¡ç†
if "chat_history" not in st.session_state:
    st.session_state.chat_history = deque(maxlen=20)

# åˆ†ç¦»å®æ—¶æ˜¾ç¤ºå’Œå†å²è®°å½•æ¸²æŸ“
if "pending_response" not in st.session_state:
    st.session_state.pending_response = False


def render_historical_messages():
    """æ¸²æŸ“å†å²æ¶ˆæ¯ï¼ˆæ’é™¤æ­£åœ¨å¤„ç†çš„æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰"""
    # æ’é™¤æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ­£åœ¨å¤„ç†ä¸­çš„æ¶ˆæ¯ï¼‰
    messages_to_render = list(st.session_state.chat_history)[
                         :-1] if st.session_state.pending_response else st.session_state.chat_history

    for chat in messages_to_render:
        with st.chat_message(chat["role"]):
            formatted = format_think_content(chat["content"])
            st.markdown(formatted, unsafe_allow_html=True)


def render_realtime_interaction():
    """æ¸²æŸ“å®æ—¶äº¤äº’æ¶ˆæ¯"""
    if st.session_state.pending_response:
        # æ˜¾ç¤ºæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        last_user_msg = st.session_state.chat_history[-1]
        with st.chat_message(last_user_msg["role"]):
            st.markdown(last_user_msg["content"], unsafe_allow_html=True)

        # æ˜¾ç¤ºåŠ©ç†å“åº”å ä½ç¬¦
        with st.chat_message("assistant"):
            st.session_state.response_placeholder = st.empty()


# ============== ç”¨æˆ·äº¤äº’ ==============
with st.sidebar:
    model = st.selectbox("é€‰æ‹©æ¨¡å‹", ["deepseek-r1", "llama3", "mixtral"])
    st.button("æ¸…ç©ºè®°å½•", on_click=lambda: st.session_state.chat_history.clear())

prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

if prompt and not st.session_state.pending_response:
    # æ ‡è®°å¼€å§‹å¤„ç†æ–°è¯·æ±‚
    st.session_state.pending_response = True

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    # æ„å»ºè¯·æ±‚
    history = "\n".join(
        [f"{msg['role'].capitalize()}: {msg['content']}"
         for msg in st.session_state.chat_history[:-1]]  # æ’é™¤å½“å‰æ­£åœ¨å¤„ç†çš„ç”¨æˆ·æ¶ˆæ¯
    )

    try:
        # å‘é€è¯·æ±‚
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model,
                "prompt": f"å¯¹è¯å†å²ï¼š\n{history}\nAssistant:",
                "stream": True
            },
            stream=True,
            timeout=30
        )
        response.raise_for_status()

        # æµå¼å¤„ç†
        full_response = ""
        for line in response.iter_lines():
            if line:
                data = json.loads(line.decode())
                if 'response' in data:
                    full_response += data['response']
                    # æ›´æ–°å®æ—¶æ˜¾ç¤º
                    formatted = format_think_content(full_response + "â–Œ")
                    st.session_state.response_placeholder.markdown(formatted, unsafe_allow_html=True)

        # å¤„ç†å®Œæˆ
        formatted_final = format_think_content(full_response)
        st.session_state.response_placeholder.markdown(formatted_final, unsafe_allow_html=True)

        # æ·»åŠ åŠ©ç†å“åº”åˆ°å†å²è®°å½•
        st.session_state.chat_history.append({"role": "assistant", "content": full_response})

        # å¯åŠ¨è¯­éŸ³çº¿ç¨‹
        threading.Thread(
            target=tts_speak,
            args=(full_response,),
            daemon=True
        ).start()

    except Exception as e:
        logging.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
    finally:
        # é‡ç½®å¤„ç†çŠ¶æ€
        st.session_state.pending_response = False

# é¡µé¢æ¸²æŸ“æµç¨‹
render_historical_messages()  # æ¸²æŸ“å†å²æ¶ˆæ¯
render_realtime_interaction()  # æ¸²æŸ“å®æ—¶äº¤äº’