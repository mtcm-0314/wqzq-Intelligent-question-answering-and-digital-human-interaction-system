import streamlit as st
import pyttsx3
import requests
import json
import threading
import numpy as np
from sentence_transformers import SentenceTransformer
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility

# ------------------ åˆå§‹åŒ– ------------------ #
stop_speaking = threading.Event()
speak_thread = None

def create_tts_engine():
    engine = pyttsx3.init()
    engine.setProperty('rate', 150)
    engine.setProperty('volume', 1)
    return engine

def speak(text):
    global speak_thread
    stop_speaking.clear()
    engine = create_tts_engine()

    for word in text.split():
        if stop_speaking.is_set():
            break
        engine.say(word)
        engine.runAndWait()
    engine.stop()

def stop_tts():
    global speak_thread
    stop_speaking.set()
    engine = create_tts_engine()
    engine.stop()
    if speak_thread and speak_thread.is_alive():
        speak_thread.join()
    speak_thread = None

# ------------------ åµŒå…¥æ¨¡å‹ ------------------ #
embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
def get_embedding(text):
    return embedding_model.encode([text])[0].tolist()

# ------------------ Streamlit ç•Œé¢ ------------------ #
st.title("DeepSeek Chatbot ğŸ¤–")
st.write("Powered by DeepSeek + Milvus å‘é‡çŸ¥è¯†åº“")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡ç®€æ´æ¸…æ™°åœ°å›ç­”é—®é¢˜"}]

for msg in st.session_state.messages:
    if msg["role"] in ["user", "assistant"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ------------------ Milvus åˆå§‹åŒ– ------------------ #
CLUSTER_ENDPOINT = ""
TOKEN = ""

try:
    connections.connect(alias="default", uri=CLUSTER_ENDPOINT, token=TOKEN)
except Exception as e:
    st.error(f"âŒ è¿æ¥ Milvus å¤±è´¥: {e}")
    st.stop()

collection_name = "chatbot_collection"
existing_collections = utility.list_collections()

if collection_name not in existing_collections:
    id_field = FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True)
    text_field = FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500)
    vector_field = FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)
    schema = CollectionSchema(fields=[id_field, text_field, vector_field])
    collection = Collection(name=collection_name, schema=schema)
else:
    collection = Collection(name=collection_name)

# ------------------ æ£€ç´¢å‡½æ•° ------------------ #
def search_similar_docs(query_text, top_k=3):
    query_vector = get_embedding(query_text)
    search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["text"]
    )
    hits = results[0]
    return [hit.entity.get("text") for hit in hits]

# ------------------ ç”¨æˆ·è¾“å…¥ & DeepSeek ------------------ #
DEEPSEEK_API_URL = ""
API_KEY = ""
MODEL_NAME = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"

user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")

if user_input:
    stop_tts()
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # ğŸ‘‰ å‘é‡æ’å…¥
    user_embedding = get_embedding(user_input)
    insert_result = collection.insert([[user_input], [user_embedding]])
    st.write("ğŸ”— å·²å­˜å…¥ Milvus, ä¸»é”®ä¸º:", insert_result.primary_keys)

    # ğŸ” æ£€ç´¢ä¸Šä¸‹æ–‡
    related_docs = search_similar_docs(user_input, top_k=3)
    knowledge_context = "\n".join(related_docs)
    system_prompt = f"ä½ æ˜¯ä¸€ä¸ªèªæ˜çš„ AI åŠ©æ‰‹ï¼Œè¯·å‚è€ƒä»¥ä¸‹çŸ¥è¯†å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\n{knowledge_context}"
    context_messages = [{"role": "system", "content": system_prompt}] + st.session_state.messages[-10:]

    # ğŸš€ è°ƒç”¨ DeepSeek æ¥å£
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": MODEL_NAME,
        "messages": context_messages,
        "stream": True,
        "temperature": 0.7,
        "max_tokens": 1024
    }

    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload, stream=True, timeout=(10, 30))
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            for chunk in response.iter_lines():
                if chunk:
                    decoded_chunk = chunk.decode('utf-8').strip()
                    if decoded_chunk == "data: [DONE]":
                        break
                    if decoded_chunk.startswith("data: "):
                        try:
                            json_data = json.loads(decoded_chunk[6:])
                            delta = json_data["choices"][0].get("delta", {})
                            chunk_content = delta.get("content", "")
                            if chunk_content:
                                full_response += chunk_content
                                message_placeholder.markdown(full_response + "â–Œ")
                        except json.JSONDecodeError:
                            st.error(f"JSON è§£æå¤±è´¥: {decoded_chunk}")

            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            speak_thread = threading.Thread(target=speak, args=(full_response,))
            speak_thread.start()
    except requests.RequestException as e:
        st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")

# ------------------ åœæ­¢æœ—è¯»æŒ‰é’® ------------------ #
if st.button("åœæ­¢æœ—è¯»"):
    stop_tts()
