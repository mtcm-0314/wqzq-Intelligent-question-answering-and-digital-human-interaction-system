import streamlit as st
import pyttsx3
import requests
import json
import threading
from sentence_transformers import SentenceTransformer
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from streamlit.components.v1 import html
from parts.voice_input_component import voice_input_component
from streamlit_js_eval import streamlit_js_eval
import numpy as np
# ------------------ åˆå§‹åŒ– ------------------ #
live2d_js = """
<script src="https://fastly.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script>
"""
html(live2d_js, height=400)

stop_speaking = threading.Event()
speak_thread = None

def create_tts_engine():
    engine = pyttsx3.init()
    engine.setProperty('rate', 150)
    engine.setProperty('volume', 1)
    return engine

def speak(text):
    global speak_thread
    stop_speaking.clear()
    engine = create_tts_engine()
    for word in text.split():
        if stop_speaking.is_set():
            break
        engine.say(word)
        engine.runAndWait()
    engine.stop()

def stop_tts():
    global speak_thread
    stop_speaking.set()
    engine = create_tts_engine()
    engine.stop()
    if speak_thread and speak_thread.is_alive():
        speak_thread.join()
    speak_thread = None

# ------------------ åµŒå…¥æ¨¡å‹ ------------------ #
embedding_model = SentenceTransformer(r'C:\Users\mtcm\Desktop\ä¸œç›Ÿæ¯\code\local_embedding_model')

def get_embedding(text):
    return embedding_model.encode([text])[0].tolist()

# ------------------ Streamlit UI ------------------ #
st.title("ğŸ’¬ DeepSeek + Ollama æœ¬åœ°é—®ç­”æœºå™¨äºº")
st.write("æ”¯æŒæœ¬åœ° Ollama æ¨¡å‹ã€Milvus æ£€ç´¢ã€æµå¼å“åº”ã€è¯­éŸ³æ’­æ”¾")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡ç®€æ´æ¸…æ™°åœ°å›ç­”é—®é¢˜"}]

for msg in st.session_state.messages:
    if msg["role"] in ["user", "assistant"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ------------------ Milvus åˆå§‹åŒ– ------------------ #
CLUSTER_ENDPOINT = "https://in03-4bb3b5dc9f774d4.serverless.ali-cn-hangzhou.cloud.zilliz.com.cn"
TOKEN = "358abb9a79b57207731d57cc"

try:
    connections.connect(alias="default", uri=CLUSTER_ENDPOINT, token=TOKEN)
except Exception as e:
    st.error(f"âŒ è¿æ¥ Milvus å¤±è´¥: {e}")
    st.stop()

collection_name = "guilin_qa_collection"
existing_collections = utility.list_collections()

if collection_name not in existing_collections:
    id_field = FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True)
    text_field = FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=500)
    vector_field = FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=384)
    # ä¿®æ”¹ FieldSchema å®šä¹‰ï¼ˆæ·»åŠ  FLOAT ç±»å‹çš„ weight å­—æ®µï¼‰
    weight_field = FieldSchema(name="weight", dtype=DataType.FLOAT)  # æƒé‡å­—æ®µ
    schema = CollectionSchema(
        fields=[id_field, text_field, vector_field, weight_field]  # åŠ å…¥ weight
    )
    # schema = CollectionSchema(fields=[id_field, text_field, vector_field])
    collection = Collection(name=collection_name, schema=schema)
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "L2",
        "params": {"nlist": 128}
    }
    collection.create_index(field_name="embedding", index_params=index_params)
else:
    collection = Collection(name=collection_name)

collection.load()

# ------------------ æ£€ç´¢å‡½æ•° ------------------ #
# def search_similar_docs(query_text, top_k=3):
#     query_vector = get_embedding(query_text)
#     search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
#     results = collection.search(
#         data=[query_vector],
#         anns_field="embedding",
#         param=search_params,
#         limit=top_k,
#         output_fields=["text"]
#     )
#     hits = results[0]
#     return [hit.entity.get("text") for hit in hits]
def search_similar_docs(query_text, top_k=3):
    query_vector = get_embedding(query_text)
    search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=top_k * 2,  # å¤šå–ä¸€äº›ç»“æœç”¨äºåç»­åŠ æƒ
        output_fields=["text", "weight"]
    )

    hits = results[0]
    # è®¡ç®—åŠ æƒå¾—åˆ†
    weighted_results = []
    for hit in hits:
        score = hit.score
        # st.write("score:", score)
        text = hit.entity.get("text")
        # st.write("text:", text)
        weight = hit.entity.get("weight")  # é»˜è®¤æƒé‡1.0
        # st.write("weight:", weight)
        # weighted_score = score * weight
        weighted_score = score * (1 + np.log(weight + 1))
        weighted_results.append((text, weighted_score))

    # æŒ‰åŠ æƒå¾—åˆ†æ’åº
    weighted_results.sort(key=lambda x: x[1], reverse=True)

    # è¿”å›å‰top_kä¸ªç»“æœ
    return [result[0] for result in weighted_results[:top_k]]
# ------------------ æœ¬åœ° OLLAMA è®¾ç½® ------------------ #
OLLAMA_API_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "deepseek-r1"

# ------------------ ç”¨æˆ·è¾“å…¥ & ä¸»é€»è¾‘ ------------------ #
# åœ¨é¡µé¢ä¸ŠåŠ è½½è¯­éŸ³è¯†åˆ«ç»„ä»¶
voice_input_component()

# å°è¯•è·å–è¯†åˆ«ç»“æœ
transcript = streamlit_js_eval(js_expressions="window._lastVoiceTranscript", key="voice_input")

if transcript and transcript.strip():
    st.session_state.voice_input = transcript.strip()
    st.experimental_rerun()

# æ£€æŸ¥æ˜¯å¦æœ‰è¯­éŸ³è¾“å…¥å†…å®¹
user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...") or st.session_state.pop("voice_input", "")

if user_input:
    stop_tts()
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    try:
        user_embedding = get_embedding(user_input)
    except Exception as e:
        st.error(f"âŒ è·å–åµŒå…¥å¤±è´¥: {e}")
        st.stop()

    try:
        related_docs = search_similar_docs(user_input, top_k=10)
        knowledge_context = "\n".join(related_docs)
        system_prompt = f"ä½ æ˜¯ä¸€ä¸ªèªæ˜çš„ AI åŠ©æ‰‹ï¼Œè¯·å‚è€ƒä»¥ä¸‹çŸ¥è¯†å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\n{knowledge_context}"
    except Exception as e:
        st.error(f"âŒ Milvus æ£€ç´¢å¤±è´¥: {e}")
        st.stop()

    context_messages = [{"role": "system", "content": system_prompt}] + st.session_state.messages[-10:]

    full_prompt = ""
    for msg in context_messages:
        role = msg["role"]
        content = msg["content"]
        if role == "user":
            full_prompt += f"ç”¨æˆ·: {content}\n"
        elif role == "assistant":
            full_prompt += f"åŠ©æ‰‹: {content}\n"
        elif role == "system":
            full_prompt += f"{content}\n"

    try:
        payload = {
            "model": MODEL_NAME,
            "prompt": full_prompt,
            "stream": True
        }
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            response = requests.post(OLLAMA_API_URL, json=payload, stream=True, timeout=(10, 30))
            for line in response.iter_lines():
                if line:
                    data = json.loads(line.decode("utf-8"))
                    content = data.get("response", "")
                    full_response += content
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            speak_thread = threading.Thread(target=speak, args=(full_response,))
            speak_thread.start()

    except Exception as e:
        st.error(f"âŒ Ollama æœ¬åœ°æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")

# ------------------ åœæ­¢æœ—è¯»æŒ‰é’® ------------------ #
if st.button("ğŸ›‘ åœæ­¢æœ—è¯»"):
    stop_tts()
